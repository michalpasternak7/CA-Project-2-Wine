{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \n",
    "from scipy import stats\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.discriminant_analysis import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, cohen_kappa_score, f1_score\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "red_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "white_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted data (duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lines that have all values duplicated\n",
    "red_wine.drop_duplicates(inplace=True, ignore_index=True)\n",
    "white_wine.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data - luckily there is none, but let's confirm that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data\n",
    "red_wine.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data\n",
    "white_wine.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add quality labels and combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add quality_label column\n",
    "for wine_df in [red_wine, white_wine]:\n",
    "    # we are creating a new column called \"quality_label\", we define a range and associate that range with a label\n",
    "    wine_df['quality_label'] = wine_df['quality'].apply(lambda value: 'low'\n",
    "    if value <= 5 else 'medium'\n",
    "    if value <= 7 else 'high')\n",
    "\n",
    "    # here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "    wine_df['quality_label'] = pd.Categorical(wine_df['quality_label'],\n",
    "    categories=['low', 'medium', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove quality column (we are going to use quality labels only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop quality column\n",
    "for wine_df in [red_wine, white_wine]:\n",
    "    wine_df.drop(['quality'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a df with both wine types with a column indicating color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column with color of wine\n",
    "red_wine['color'] = 'red'\n",
    "white_wine['color'] = 'white'\n",
    "\n",
    "# combine the wine dfs\n",
    "wine = pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "wine['color'] = pd.Categorical(wine['color'],\n",
    "categories=['red', 'white'])\n",
    "\n",
    "# drop the color from red and white wind dfs (it's not necessary there)\n",
    "red_wine.drop(['color'], axis=1, inplace=True)\n",
    "white_wine.drop(['color'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the rename method to change all columns names lowercase and add an underscore if they are made of 2 words\n",
    "for wine_df in [wine, red_wine, white_wine]:\n",
    "    wine_df.rename(str.lower, axis='columns', inplace=True)  # make the names lowercase\n",
    "    wine_df.columns = wine_df.columns.str.replace(' ', '_')     # replace space with underscore in column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine quality class distribution. It's very unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the main focus is on quality, let's have a look on how it is distributed.\n",
    "\n",
    "# set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# create a figure with two side-by-side histograms\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "# plot the first histplot on the left (axes[0])\n",
    "sns.histplot(data=white_wine, x='quality_label', color='lightgreen', stat='percent', ax=axes[0])\n",
    "axes[0].set_title('White Wine')\n",
    "axes[0].set_xlabel('Wine Quality')\n",
    "\n",
    "# plot the second histplot on the right (axes[1])\n",
    "sns.histplot(data=red_wine, x='quality_label', color='red', stat='percent', ax=axes[1])\n",
    "axes[1].set_title('Red Wine')\n",
    "axes[1].set_xlabel('Wine Quality')\n",
    "\n",
    "# adjust layout is used to adjust the layout so that the plots don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the main focus is on quality, let's have a look on how it is distributed.\n",
    "\n",
    "# set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# plot the first histplot on the left (axes[0])\n",
    "sns.histplot(data=wine, x='quality_label', color='blue', stat='percent')\n",
    "\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.xlabel('Wine Quality')  # set the x-axis label\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['quality_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the color (for the machine learning they are required to be numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of OneHotEncoder\n",
    "oh_enc = OneHotEncoder(categories=[['red','white']])\n",
    "\n",
    "# fit and transform the 'color' column\n",
    "encoded_color = oh_enc.fit_transform(wine[['color']])\n",
    "\n",
    "# convert the one-hot encoded data to a DataFrame\n",
    "encoded_color_df = pd.DataFrame(encoded_color.toarray(), columns=oh_enc.get_feature_names_out(['color']))\n",
    "\n",
    "# concatenate the one-hot encoded DataFrame with 'wine_ml'\n",
    "wine = pd.concat([wine, encoded_color_df], axis=1)\n",
    "\n",
    "# drop the original 'color' column from 'wine_ml'\n",
    "wine = wine.drop('color', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the quality labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the quality labels with numerical values\n",
    "for wine_df in [wine, red_wine, white_wine]:\n",
    "    quality_codes = {'low' : 0, 'medium' : 1, 'high' : 2}\n",
    "    wine_df['quality_label'].replace(quality_codes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop(['quality_label'], axis=1) # features\n",
    "y = wine['quality_label']  # target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Undersampling (to balance the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Undersampling\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Choose a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common algorithms which are used for Multi-Class Classification are :\n",
    "\n",
    "- K-Nearest Neighbours\n",
    "- Naive Bayes\n",
    "- Decision trees\n",
    "- Gradient Boosting\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_statistics(model, X_train, X_test, y_train, y_test, n=1):\n",
    "\n",
    "    metrics_list = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        # train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # calculate evaluation metrics\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_pred, y_test)\n",
    "\n",
    "        metrics_list.append({\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'kappa': kappa\n",
    "        })\n",
    "\n",
    "    # calculate average and standard deviation\n",
    "    avg_metrics = {k: np.mean([m[k] for m in metrics_list]) for k in metrics_list[0]}\n",
    "    std_metrics = {k: np.std([m[k] for m in metrics_list]) for k in metrics_list[0]}\n",
    "\n",
    "    return {\n",
    "        'average_metrics': avg_metrics,\n",
    "        'std_metrics': std_metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "evaluation_results = evaluate_model_with_statistics(rf, X_train, X_test, y_train, y_test, n=10)\n",
    "pd.DataFrame.from_dict(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with undersampled data\n",
    "evaluation_results = evaluate_model_with_statistics(rf, X_resampled, X_test, y_resampled, y_test, n=10)\n",
    "pd.DataFrame.from_dict(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_confusion_matrix(model, X_train, X_test, y_train, y_test, n=10, precision=2):\n",
    "\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Generate a confusion matrix\n",
    "        matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        confusion_matrices.append(matrix)\n",
    "\n",
    "    # Calculate the average confusion matrix\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "    # Set the precision for printing\n",
    "    np.set_printoptions(precision=precision, suppress=True)\n",
    "\n",
    "    return avg_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "conf_matrix = average_confusion_matrix(rf, X_train, X_test, y_train, y_test, n=10, precision=2)\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with undersampled data\n",
    "conf_matrix = average_confusion_matrix(rf, X_resampled, X_test, y_resampled, y_test, n=10, precision=2)\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5,\n",
    "                                 random_state=0)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the best model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
